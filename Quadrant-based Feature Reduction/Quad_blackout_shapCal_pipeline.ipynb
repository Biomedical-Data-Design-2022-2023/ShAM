{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNGqw+JynkFvgNR1F4OO2pM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":9,"metadata":{"id":"pcZpaR0sbF41","executionInfo":{"status":"ok","timestamp":1684373739623,"user_tz":240,"elapsed":112,"user":{"displayName":"Siyu Wang","userId":"01810863136484305973"}}},"outputs":[],"source":["import cv2\n","import matplotlib.pyplot as plt\n","from itertools import chain, combinations\n","import numpy as np\n","from PIL import Image\n","\n","import torch\n","from sklearn.decomposition import PCA\n","from sklearn.cluster import KMeans\n","import pandas as pd\n","from tqdm import tqdm\n","import os\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","import torchvision\n","import itertools\n","import matplotlib.patches as patches\n","from torchvision import transforms\n","from PIL import Image\n","from itertools import combinations \n","import math\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cszc8dRsboju","executionInfo":{"status":"ok","timestamp":1684373613060,"user_tz":240,"elapsed":72343,"user":{"displayName":"Siyu Wang","userId":"01810863136484305973"}},"outputId":"5f2fe460-15bd-4d33-b2c4-ff8db23a5ac1"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["image_name = \"1f8f08ea-b5b3-4f68-94d4-3cc071b7dce8.png\"\n","root_path = \"/content/drive/MyDrive/Colab Notebooks/\"\n","image_path = root_path + image_name\n","shap_image_path = root_path + 'Shap_image/'"],"metadata":{"id":"BmEHevh_b8od","executionInfo":{"status":"ok","timestamp":1684373847792,"user_tz":240,"elapsed":115,"user":{"displayName":"Siyu Wang","userId":"01810863136484305973"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def mask_generate(I,k,grey_area):\n","    \"\"\"\n","    assign quadents of the image to black (masking certain region of the image to black)\n","    input: \n","      I: image \n","      k: quadents index \n","      grey area: quadents indexs that to be black out\n","    output: \n","      I_copy: is the blacked out masked image\n","    \"\"\"\n","    I_copy = I.copy()\n","    shape1=I.shape[0]//(2**k)\n","    shape2=I.shape[1]//(2**k)\n","    for i in range(len(grey_area)):\n","        row=grey_area[i]//(2**k)\n","        col=grey_area[i]-row*(2**k)\n","        if col==0:\n","            col=2**k\n","        col-=1\n","        startr=row*shape1;endr=(row+1)*shape1\n","        startc=col*shape2;endc=(col+1)*shape2\n","        I_copy[startr:endr,startc:endc,:]=0\n","    return I_copy"],"metadata":{"id":"L6K5AOtubo5v","executionInfo":{"status":"ok","timestamp":1684373613061,"user_tz":240,"elapsed":3,"user":{"displayName":"Siyu Wang","userId":"01810863136484305973"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def generate_combinations(num_parts):\n","    '''\n","    generate all combinations of different players (total of num_parts players)\n","    input: \n","      num_parts: total number of players\n","    output: \n","      combination_list: list of all different combinations\n","    '''\n","    list_parts = list(range(num_parts))\n","    combination_list = []\n","    for i in range(num_parts+1):\n","        combination_list_curr = list(combinations(list_parts,i))\n","        combination_list = combination_list + combination_list_curr\n","    return combination_list\n","\n","def generate_masked_images(I,k, num_parts, save_dir, isSmall):\n","    '''\n","    generate all black out images with all different combinations\n","    input: \n","      I: image \n","      k: player index \n","      num_parts: total number of players\n","      save_dir: the directory to save the black out masked image \n","      isSmall: if output a small size image (small 256*256*3, if not small 1200*1600*3)\n","    '''\n","    grey_area_list_tuple = generate_combinations(num_parts)\n","    grey_area_list = []\n","    for i in range(len(grey_area_list_tuple)):\n","        grey_area_list.append(list(grey_area_list_tuple[i]))\n","    # print(grey_area_list)\n","    for i in range(len(grey_area_list)):\n","        print(list(grey_area_list[i]))\n","        I_m = mask_generate(I, k, grey_area_list[i])\n","        # plt.imshow(I_m)\n","        # print(I_m.shape)\n","        if isSmall == False: \n","            if len(grey_area_list[i]) > 0:\n","                for j in range(len(grey_area_list[i])):\n","                    grey_area_list[i][j] = grey_area_list[i][j] + 1\n","                myString = ''.join(map(str,grey_area_list[i]))\n","                # print(\"/output_\"+myString+\".png\")\n","                I_m.save(save_dir+\"/output_\"+myString+\".png\")\n","            else: \n","                I_m.save(save_dir+\"/output_.png\")\n","        else: \n","            newsize = (256, 256)\n","            I_m_copy = I_m.copy()\n","            plt.imshow(I_m_copy)\n","            I_m_r = cv2.resize(I_m_copy,newsize)\n","            I_m_r_image = Image.fromarray(I_m_r, \"RGB\")\n","            if len(grey_area_list[i]) > 0:\n","                for j in range(len(grey_area_list[i])):\n","                    grey_area_list[i][j] = grey_area_list[i][j] + 1\n","                myString = ''.join(map(str,grey_area_list[i]))\n","                # print(\"/output_\"+myString+\".png\")\n","                I_m_r_image.save(save_dir+\"/output_\"+myString+\".png\")\n","            else: \n","                I_m_r_image.save(save_dir+\"/output_.png\")\n","    return grey_area_list"],"metadata":{"id":"9J7_v2SScEUF","executionInfo":{"status":"ok","timestamp":1684374189798,"user_tz":240,"elapsed":98,"user":{"displayName":"Siyu Wang","userId":"01810863136484305973"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["def excluded_list_generation(num_of_players):\n","  \"\"\"Generate list of combination of players based on num_of_player\n","  :param num_of_players: integer representing number of player\n","  :return: combination\n","  \"\"\"\n","  numbers = list(range(num_of_players))\n","  combinations = []\n","  for r in range(len(numbers)+1):\n","      for combination in itertools.combinations(numbers, r):\n","          combinations.append(list(combination))\n","  return combinations\n","\n","def get_model_result(image, model):\n","    \"\"\"Return binary classifier result of a model\n","    :param image: image to be analyzed\n","    :param model: pytorch classifier model\n","    :return: probability of being class 1\n","    \"\"\"\n","    mean = torch.tensor([0.485, 0.456, 0.406])\n","    std = torch.tensor([0.229, 0.224, 0.225])\n","    transform = transforms.Compose(\n","        [transforms.ToTensor(), \n","        transforms.Normalize(mean=mean, std=std),\n","        ]\n","    )\n","    prep_img = transform(image).to(device)\n","    prep_img = torch.unsqueeze(torch.tensor(prep_img).float(), 0)\n","    prob_scores = model(prep_img).cpu().detach().numpy()[0]\n","    p = prob_scores[1]\n","    return p\n","\n","# Code for Shapley value calculation\n","def exclude_k_matrics_calculation(k,directory, M, model):\n","    \"\"\"Calculate prediction score for patched images excluding player k\n","\n","    :param k: integer representing player k\n","    :param directory: directory contains intermediate images\n","    :param M: integer represents the number of player\n","    :param model: pytorch model\n","    :return:\n","    list of all player combinations that excludes player k,\n","    corresponding team index of each of the player combinations that excludes player k\n","    list of players\n","    corresponding prediction probability of containing sick cell\n","    list of all player combinations that includes player k,\n","    corresponding team index of each of the player combinations that includes player k\n","    \"\"\"\n","    exclude_player2_list = []\n","    exclude_player2_team_index_list = []\n","    player_list = []\n","    probList = []\n","    contains_player2_list = []\n","    contains_player2_team_index_list = []\n","    team_index = 0 \n","    all_players = list(range(1,M+1))\n","\n","    mean = torch.tensor([0.485, 0.456, 0.406])\n","    std = torch.tensor([0.229, 0.224, 0.225])\n","    transform = transforms.Compose(\n","        [transforms.ToTensor(), \n","        transforms.Normalize(mean=mean, std=std),\n","        ]\n","    )\n","    \n","    for filename in os.listdir(directory):\n","            f = os.path.join(directory, filename)\n","            # checking if it is a file\n","            if os.path.isfile(f) and f[-4:] == '.png' and \"output\" in filename:\n","                ext = filename[7:-4] # if large 16 if small 7\n","                # print(ext)\n","                players_excluded = list(ext)\n","                players_excluded = [int(i) for i in players_excluded]\n","                players = all_players.copy()\n","                for excludedPalyerId in players_excluded: \n","                    players.remove(excludedPalyerId)\n","                if k in players:\n","                    contains_player2_list.append(players)\n","                    contains_player2_team_index_list.append(team_index)\n","                else: \n","\n","                    exclude_player2_list.append(players)\n","                    exclude_player2_team_index_list.append(team_index)\n","                player_list.append(players)\n","                image = Image.open(directory+\"/\"+filename).convert('RGB')\n","                image_t = image\n","                print(image_t)\n","                prep_img = transform(image_t).to(device)\n","                \n","                prep_img = torch.unsqueeze(torch.tensor(prep_img).float(), 0)\n","                prob_scores = model(prep_img).cpu().detach().numpy()[0]\n","                p = prob_scores[1]\n","                probList.append(p)\n","                team_index += 1\n","    return exclude_player2_list, exclude_player2_team_index_list, player_list, probList, contains_player2_list, contains_player2_team_index_list\n","\n","\n","def shap_k_calulation(k, exclude_playerk_list, exclude_playerk_team_index_list, player_list, probList, contains_playerk_list, contains_playerk_team_index_list, M):\n","    \"\"\" Calculate the shapley value for player k\n","\n","    :param k: player k\n","    :param exclude_playerk_list: list of all player combinations that excludes player k\n","    :param exclude_playerk_team_index_list: corresponding team index of each of the player combinations that excludes player k\n","    :param player_list: list of players\n","    :param probList: corresponding prediction probability of containing sick cell\n","    :param contains_playerk_list: list of all player combinations that includes player k\n","    :param contains_playerk_team_index_list: corresponding team index of each of the player combinations that includes player k\n","    :param M: num of players\n","    :return: shapley value\n","    \"\"\"\n","    shap_k = 0\n","    for i, teams_withk in enumerate(contains_playerk_list):\n","        \n","        teams_withoutk = teams_withk.copy()\n","        teams_withoutk.remove(k)\n","        subset_size = len(teams_withoutk)\n","        prob_excluded = probList[exclude_playerk_team_index_list[exclude_playerk_list.index(teams_withoutk)]]\n","        # print(\"---\")\n","        # print(teams_withoutk)\n","        # print(prob_excluded)\n","        # print(exclude_playerk_team_index_list[exclude_playerk_list.index(teams_withoutk)])\n","        prob_with = probList[contains_playerk_team_index_list[i]]\n","        # print(teams_withk)\n","        # print(prob_with)\n","        shap_k = shap_k + (math.factorial(subset_size)*math.factorial(M-subset_size-1))*(prob_with-prob_excluded)/math.factorial(M)\n","        # print(contains_playerk_team_index_list[i])\n","    print(\"the shap value of {} is: {} \".format(k,shap_k))\n","    return shap_k\n","\n","\n","def shap_main(k_list, directory, M, model):\n","    \"\"\"Run Shapley Calculation for model by assessing each player in k_list with images we obtained from directory\n","\n","    :param k_list: a list contains players (integers)\n","    :param directory: directory contains images\n","    :param M: int represents number of player\n","    :param model: model for Shapley value evaluations\n","    :return: a list in the format of [(player_id, shapley_score), ...]\n","    \"\"\"\n","    shap_value_list = []\n","    for k in k_list:     \n","        print(\"====================== looking at k=\" + str(k))\n","        exclude_playerk_list, exclude_playerk_team_index_list, player_list, probList, contains_playerk_list, contains_playerk_team_index_list = exclude_k_matrics_calculation(k,directory, M, model)\n","        # print(probList)\n","        shap_k = shap_k_calulation(k, exclude_playerk_list, exclude_playerk_team_index_list, player_list, probList, contains_playerk_list, contains_playerk_team_index_list, M)\n","        shap_value_list.append([k,shap_k])\n","    return shap_value_list"],"metadata":{"id":"T6ZwLkKwdep3","executionInfo":{"status":"ok","timestamp":1684373613062,"user_tz":240,"elapsed":4,"user":{"displayName":"Siyu Wang","userId":"01810863136484305973"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Load the classifier\n","device = \"cuda\"\n","filename = root_path + 'model_git.pt'\n","model_git = torch.hub.load(\"pytorch/vision:v0.10.0\", \"resnet18\", pretrained=False)\n","num_ftrs = model_git.fc.in_features\n","model_git.fc = nn.Linear(num_ftrs, 2)\n","model_git.load_state_dict(torch.load(filename, map_location=device))\n","model_git = model_git.to(device)\n","model_git.eval()\n","torch.cuda.empty_cache()\n","model_git = nn.Sequential(\n","    model_git,\n","    nn.Softmax(dim=1),\n",")\n","print(model_git)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V9lxdyU6iEeV","executionInfo":{"status":"ok","timestamp":1684374370394,"user_tz":240,"elapsed":6898,"user":{"displayName":"Siyu Wang","userId":"01810863136484305973"}},"outputId":"8d2b4cd9-ebeb-4e0c-d4a7-9a035e7c3ae0"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to /root/.cache/torch/hub/v0.10.0.zip\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["Sequential(\n","  (0): ResNet(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","    (fc): Linear(in_features=512, out_features=2, bias=True)\n","  )\n","  (1): Softmax(dim=1)\n",")\n"]}]},{"cell_type":"code","source":["image = cv2.imread(image_path) # load prediction model\n","image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"],"metadata":{"id":"MHe4JidJe8QO","executionInfo":{"status":"ok","timestamp":1684373860101,"user_tz":240,"elapsed":584,"user":{"displayName":"Siyu Wang","userId":"01810863136484305973"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["k_list = generate_masked_images(image,1, 4, shap_image_path, True) # generate the masked images "],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":721},"id":"oXVKeYPpfrJO","executionInfo":{"status":"ok","timestamp":1684374247189,"user_tz":240,"elapsed":5628,"user":{"displayName":"Siyu Wang","userId":"01810863136484305973"}},"outputId":"93678d72-702a-4eb7-8722-c21c5bb4b7f2"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["[]\n","[0]\n","[1]\n","[2]\n","[3]\n","[0, 1]\n","[0, 2]\n","[0, 3]\n","[1, 2]\n","[1, 3]\n","[2, 3]\n","[0, 1, 2]\n","[0, 1, 3]\n","[0, 2, 3]\n","[1, 2, 3]\n","[0, 1, 2, 3]\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["shap_value_list = shap_main([1,2,3,4], shap_image_path, 4, model_git) # run shapley calculation"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d0-jxvpUhVYR","executionInfo":{"status":"ok","timestamp":1684374435840,"user_tz":240,"elapsed":602,"user":{"displayName":"Siyu Wang","userId":"01810863136484305973"}},"outputId":"c7378472-92a2-4d01-f3af-ea1e5539f814"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["====================== looking at k=1\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EFE8D6110>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF8181A20>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF81815D0>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF81822C0>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF8181210>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF8180F10>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF8181A20>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF81813C0>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF8181210>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF8181A20>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF8183F10>\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-d83fb28edad4>:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  prep_img = torch.unsqueeze(torch.tensor(prep_img).float(), 0)\n"]},{"output_type":"stream","name":"stdout","text":["<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF81813C0>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF8183CD0>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF8181150>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF8181360>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF8181A20>\n","the shap value of 1 is: 0.12230874318629503 \n","====================== looking at k=2\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF81831C0>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF8181A20>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF8180610>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF8181A20>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF8180610>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF81831C0>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF81810F0>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF8181150>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF81825F0>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF8183CD0>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF81810F0>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF8181150>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF81813C0>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF8181A20>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF8180610>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF81831C0>\n","the shap value of 2 is: 0.012184137323250384 \n","====================== looking at k=3\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF81822C0>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF81831C0>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF81825F0>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF8183F10>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF8181150>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF81822C0>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF8181660>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF81825F0>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF81812D0>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF8181150>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF81812D0>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF8181660>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF81822C0>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF8181660>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF8181150>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF81815D0>\n","the shap value of 3 is: 0.713474699606498 \n","====================== looking at k=4\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF81813C0>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF81825F0>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF81813C0>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF8181360>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF81813C0>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF81825F0>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF81822C0>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF81813C0>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF81822C0>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF81825F0>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF81822C0>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF8181150>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF81810F0>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF81825F0>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF81810F0>\n","<PIL.Image.Image image mode=RGB size=256x256 at 0x7F9EF81822C0>\n","the shap value of 4 is: 0.14027499252309403 \n"]}]},{"cell_type":"code","source":["print(shap_value_list)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WlzjRaTeiYBd","executionInfo":{"status":"ok","timestamp":1684374439525,"user_tz":240,"elapsed":97,"user":{"displayName":"Siyu Wang","userId":"01810863136484305973"}},"outputId":"43d26ffe-e9b9-4949-8abe-7d2185f4936a"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1, 0.12230874318629503], [2, 0.012184137323250384], [3, 0.713474699606498], [4, 0.14027499252309403]]\n"]}]}]}